{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89b022a-fbb7-400a-9ee7-48545f94addf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1d4cb-65dd-4c90-971c-931d589ba94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to generate points at a specified interval along a line\n",
    "def generate_points_along_line(line, interval):\n",
    "    points = []\n",
    "    length = line.length\n",
    "    distance = 0\n",
    "    while distance < length:\n",
    "        point = line.interpolate(distance)\n",
    "        points.append(point)\n",
    "        distance += interval\n",
    "    return gpd.GeoSeries(points)\n",
    "\n",
    "def find_perpendicular_points(point, path_points, segment_length=10):\n",
    "    # Find the index of the closest point on the path\n",
    "    distances = np.sqrt(((path_points - point)**2).sum(axis=1))\n",
    "    closest_index = np.argmin(distances)\n",
    "    \n",
    "    # Use the closest points to approximate the derivative\n",
    "    if closest_index == 0:  # If the closest is the first point, take the next point to calculate the slope\n",
    "        next_index = 1\n",
    "    elif closest_index == len(path_points) - 1:  # If the closest is the last point, take the previous point\n",
    "        next_index = closest_index - 1\n",
    "    else:\n",
    "        # Take the next or previous point which is closer to calculate the slope\n",
    "        if distances[closest_index + 1] < distances[closest_index - 1]:\n",
    "            next_index = closest_index + 1\n",
    "        else:\n",
    "            next_index = closest_index - 1\n",
    "    \n",
    "    # Calculate the slope of the path at the closest point\n",
    "    dy = path_points[next_index, 1] - path_points[closest_index, 1]\n",
    "    dx = path_points[next_index, 0] - path_points[closest_index, 0]\n",
    "    \n",
    "    if dx == 0:  # Avoid division by zero\n",
    "        perp_slope = 0\n",
    "    else:\n",
    "        perp_slope = -dx / dy\n",
    "    \n",
    "    # Calculate the mid-point for the perpendicular line segment\n",
    "    mid_x, mid_y = point\n",
    "    \n",
    "    # Calculate the dx and dy for the perpendicular segment\n",
    "    if perp_slope == 0:  # Horizontal line\n",
    "        dx_perp = 0\n",
    "        dy_perp = segment_length / 2\n",
    "    else:\n",
    "        dx_perp = segment_length / (2 * np.sqrt(1 + perp_slope**2))\n",
    "        dy_perp = perp_slope * dx_perp\n",
    "    \n",
    "    # Calculate the two ends of the perpendicular segment\n",
    "    start_point = (mid_x - dx_perp, mid_y - dy_perp)\n",
    "    end_point = (mid_x + dx_perp, mid_y + dy_perp)\n",
    "    \n",
    "    return start_point, end_point\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239454cc-2b73-49f7-b714-ba8fb50be3a5",
   "metadata": {},
   "source": [
    "# Download Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961286c-865b-4c3c-bf1c-247ef26f5bf0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### WORKS WITH NO BOARDER!\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "# # Specify the directory where your TIFF files are located\n",
    "# tif_dir = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\FIRE\\AUGUST\"\n",
    "# output_tif_hag = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\AUGUST_hag.tif\"\n",
    "# output_tif_dtm = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\AUGUST_DTM.tif\"\n",
    "\n",
    "# tif_dir = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\FIRE\\BEAR\"\n",
    "# output_tif_hag = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\BEAR_hag.tif\"\n",
    "# output_tif_dtm = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\BEAR_DTM.tif\"\n",
    "\n",
    "# tif_dir = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\FIRE\\BUSH\"\n",
    "# output_tif_hag = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\BUSH_hag.tif\"\n",
    "# output_tif_dtm = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\BUSH_DTM.tif\"\n",
    "\n",
    "# tif_dir = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\FIRE\\CALFCANYON\"\n",
    "# output_tif_hag = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\CALFCANYON_hag.tif\"\n",
    "# output_tif_dtm = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\CALFCANYON_DTM.tif\"\n",
    "\n",
    "# tif_dir = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\FIRE\\CAMERONPEAK\"\n",
    "# output_tif_hag = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\CAMERONPEAK_hag.tif\"\n",
    "# output_tif_dtm = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\CAMERONPEAK_DTM.tif\"\n",
    "\n",
    "# tif_dir = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\FIRE\\DIXIE\"\n",
    "# output_tif_hag = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\DIXIE_hag.tif\"\n",
    "# output_tif_dtm = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\DIXIE_DTM.tif\"\n",
    "\n",
    "# tif_dir = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\FIRE\\RAFAEL\"\n",
    "# output_tif_hag = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\RAFAEL_hag.tif\"\n",
    "# output_tif_dtm = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\RAFAEL_DTM.tif\"\n",
    "\n",
    "# tif_dir = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\FIRE\\SALT1\"\n",
    "# output_tif_hag = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\SALT1_hag.tif\"\n",
    "# output_tif_dtm = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\SALT1_DTM.tif\"\n",
    "\n",
    "# tif_dir = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\FIRE\\SUGAR\"\n",
    "# output_tif_hag = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\SUGAR_hag.tif\"\n",
    "# output_tif_dtm = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\SUGAR_DTM.tif\"\n",
    "\n",
    "# tif_dir = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\FIRE\\TELEGRAPH\"\n",
    "# output_tif_hag = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\TELEGRAPH_hag.tif\"\n",
    "# output_tif_dtm = r\"C:\\Users\\magst\\Desktop\\LIDARPODS\\OUTPUTLIDAR\\MERGED\\TELEGRAPH_DTM.tif\"\n",
    "\n",
    "hag_tifs = glob.glob(os.path.join(tif_dir, \"*3dep-lidar-hag*.tiff\"))\n",
    "\n",
    "# Prepare the gdal_merge command for HAG\n",
    "merge_command_hag = [\n",
    "    \"python\",\n",
    "    \"C:\\\\Users\\\\magst\\\\anaconda3\\\\envs\\\\LIDAR\\\\Scripts\\\\gdal_merge.py\",\n",
    "    \"-o\", output_tif_hag,\n",
    "    \"-n\", \"-9999\",\n",
    "    \"-a_nodata\",\"-9999\",\n",
    "    \n",
    "] + hag_tifs\n",
    "\n",
    "# Run the gdal_merge command for HAG and capture the output\n",
    "process_hag = subprocess.run(merge_command_hag, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# Check if the command for HAG was successful\n",
    "if process_hag.returncode != 0:\n",
    "    # An error occurred, print the error\n",
    "    print(\"Error occurred while merging TIFF files HAG:\")\n",
    "    print(process_hag.stderr)\n",
    "else:\n",
    "    print(\"TIFF files merged successfully for HAG.\")\n",
    "\n",
    "# Find all TIFF files that contain 'hag' in the filename\n",
    "dtm_tifs = glob.glob(os.path.join(tif_dir, \"*3dep-lidar-dtm*.tiff\"))\n",
    "\n",
    "# Prepare the gdal_merge command for DTM\n",
    "merge_command_dtm = [\n",
    "    \"python\",\n",
    "    \"C:\\\\Users\\\\magst\\\\anaconda3\\\\envs\\\\LIDAR\\\\Scripts\\\\gdal_merge.py\",\n",
    "    \"-o\", output_tif_dtm,\n",
    "    \"-n\", \"-9999\",  \n",
    "    \"-a_nodata\",\"-9999\",\n",
    "\n",
    "] + dtm_tifs\n",
    "\n",
    "# Run the gdal_merge command for DTM and capture the output\n",
    "process_dtm = subprocess.run(merge_command_dtm, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "# Check if the command for DTM was successful\n",
    "if process_dtm.returncode != 0:\n",
    "    # An error occurred, print the error\n",
    "    print(\"Error occurred while merging TIFF files DTM:\")\n",
    "    print(process_dtm.stderr)\n",
    "else:\n",
    "    print(\"TIFF files merged successfully for DTM.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad8bea-3556-41a6-907d-cc355341a4e2",
   "metadata": {},
   "source": [
    "# Points and parallel lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f6b481-8cfa-45a3-9926-c1f1a4cef5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:32613\n",
      "EPSG:32613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin-magstadt\\AppData\\Local\\Temp\\ipykernel_4724\\3658775547.py:125: UserWarning: `keep_geom_type=True` in overlay resulted in 36 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  held_pod = gpd.overlay(buffered_gdf, test_pod, how='intersection')\n",
      "C:\\Users\\admin-magstadt\\AppData\\Local\\Temp\\ipykernel_4724\\3658775547.py:144: UserWarning: `keep_geom_type=True` in overlay resulted in 23 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  breached_pod = gpd.overlay(inward_buffer_BREACH_gdf, test_pod, how='intersection')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass array with one dimension only.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 149\u001b[0m\n\u001b[0;32m    144\u001b[0m breached_pod \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39moverlay(inward_buffer_BREACH_gdf, test_pod, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintersection\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m#breached_pod = gpd.overlay(inward_buffer_BREACH, test_pod, how='intersection')\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m breached_pod_gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGeoDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbreached_pod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffered_gdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m breached_pod_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbreached_POD\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# Generate points along held_pod geometry\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ee\\lib\\site-packages\\geopandas\\geodataframe.py:188\u001b[0m, in \u001b[0;36mGeoDataFrame.__init__\u001b[1;34m(self, data, geometry, crs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(geometry, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcrs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m geometry\u001b[38;5;241m.\u001b[39mcrs\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m crs\n\u001b[0;32m    184\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m geometry\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m==\u001b[39m crs\n\u001b[0;32m    185\u001b[0m     ):\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(crs_mismatch_error)\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_geometry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m geometry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m crs:\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssigning CRS to a GeoDataFrame without a geometry column is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported. Supply geometry using the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword argument, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor by providing a DataFrame with column name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    195\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ee\\lib\\site-packages\\geopandas\\geodataframe.py:314\u001b[0m, in \u001b[0;36mGeoDataFrame.set_geometry\u001b[1;34m(self, col, drop, inplace, crs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     level \u001b[38;5;241m=\u001b[39m col\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(col, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m col\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass array with one dimension only.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass array with one dimension only."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries working for small section\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import utm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import laspy\n",
    "import gc\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.spatial import distance\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# Define a function to generate points along a line\n",
    "def generate_points_along_line(line, interval_distance):\n",
    "    total_length = line.length\n",
    "    num_points = int(total_length // interval_distance) + 1\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        point = line.interpolate(i * interval_distance)\n",
    "        points.append(point)\n",
    "    return points\n",
    "\n",
    "# Read the test POD boundary.shp\n",
    "#POD_shapefile_path = \"C:\\\\Users\\\\magst\\\\Desktop\\\\WeatherKit\\\\TestPODbndry_BUCK_2.shp\"\n",
    "POD_shapefile_path = r\"A:\\LIDARPODS\\InputData\\123456_PODs_new_dis_wgs.shp\"\n",
    "\n",
    "# Load the shapefile for the fire perimeter\n",
    "#shapefile_path_FirePerimeter = \"C:\\\\Users\\\\magst\\\\Desktop\\\\WeatherKit\\\\NIFC_2020_WFIGS_AllPerims_20231010_CAMPEAK.shp\"\n",
    "shapefile_path_FirePerimeter = r\"A:\\LIDARPODS\\InputData\\IndividualSHPFirePerimeter\\CalfCanyon_2022_perimeter.shp\"\n",
    "\n",
    "# Specify the output shapefile path\n",
    "output_shapefile_path_PTS = \"A:\\\\LIDARPODS\\\\scrap\\\\output_point_CAMPEAK.shp\"\n",
    "\n",
    "# Export the GeoDataFrame to a shapefile\n",
    "output_shp_path_PERPLINE = \"A:\\\\LIDARPODS\\\\scrap\\\\perpendicular_lines_CAMPEAK.shp\"\n",
    "\n",
    "# Define the distance interval between points (100 meters in this case)\n",
    "interval_distance = 30  # in meters\n",
    "\n",
    "# Buffer distances (m)\n",
    "buff = 550\n",
    "\n",
    "\n",
    "perp_length=500\n",
    "\n",
    "\n",
    "# Specify the threshold distance for fire perimeter label\n",
    "threshold_distance = 550\n",
    "\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "fire_perimeters = gpd.read_file(shapefile_path_FirePerimeter)\n",
    "\n",
    "# Determine the UTM zone automatically\n",
    "# Use the centroid of the first geometry to determine UTM zone\n",
    "lon, lat = fire_perimeters.geometry.iloc[0].centroid.coords[0]\n",
    "utm_zone = utm.from_latlon(lat, lon)[2]\n",
    "utm_crs = f'EPSG:326{utm_zone}'\n",
    "print(utm_crs)\n",
    "# Reproject to UTM\n",
    "fire_perimeters = fire_perimeters.to_crs(utm_crs)\n",
    "\n",
    "# buffer dist\n",
    "buffer_distance_outward = buff\n",
    "buffer_distance_inward = -buff\n",
    "\n",
    "# Create outward buffer\n",
    "outward_buffer = fire_perimeters.geometry.buffer(buffer_distance_outward)\n",
    "\n",
    "# Create inward buffer\n",
    "inward_buffer = fire_perimeters.geometry.buffer(buffer_distance_inward)\n",
    "\n",
    "buffer_distance_inward_breach = buffer_distance_inward - 300\n",
    "inward_buffer_BREACH = fire_perimeters.geometry.buffer(buffer_distance_inward_breach)\n",
    "\n",
    "# Combine buffers to create the final shape\n",
    "combined_buffers = outward_buffer.difference(inward_buffer)\n",
    "\n",
    "# Create a new GeoDataFrame\n",
    "buffered_gdf = gpd.GeoDataFrame(geometry=combined_buffers, crs=fire_perimeters.crs)\n",
    "\n",
    "################\n",
    "################\n",
    "################\n",
    "\n",
    "print(buffered_gdf.crs)\n",
    "\n",
    "test_pod = gpd.read_file(POD_shapefile_path) # From before\n",
    "\n",
    "test_pod = test_pod.to_crs(buffered_gdf.crs)\n",
    "\n",
    "# Buffer the extent of fire_perimeters by a small distance\n",
    "buffered_fire_perimeters = fire_perimeters.buffer(buff)  # Adjust the buffer distance as needed\n",
    "\n",
    "# Clip the test_pod shapefile to the buffered extent of fire_perimeters\n",
    "test_pod = gpd.clip(test_pod, buffered_fire_perimeters)\n",
    "\n",
    "# Ensure both GeoDataFrames are in the same CRS\n",
    "test_pod = test_pod.to_crs(buffered_fire_perimeters.crs)\n",
    "\n",
    "# Ensure both GeoDataFrames are in the same CRS\n",
    "#test_pod = test_pod.to_crs(buffered_gdf.crs)\n",
    "\n",
    "# Explode MultiPolygon geometries if they exist in test_pod\n",
    "if any(test_pod.geometry.type == 'MultiPolygon'):\n",
    "    test_pod = test_pod.explode(index_parts=False)\n",
    "\n",
    "# # Then try clipping again\n",
    "# held_pod = gpd.clip(buffered_gdf, test_pod)\n",
    "\n",
    "# # Clip the buffered area with the second shapefile\n",
    "# #held_pod = gpd.clip(buffered_gdf, test_pod)\n",
    "\n",
    "# # Label the clipped area\n",
    "# held_pod['label'] = 'held_POD'\n",
    "# Use overlay to perform intersection, which is similar to clipping\n",
    "held_pod = gpd.overlay(buffered_gdf, test_pod, how='intersection')\n",
    "\n",
    "# Label the intersected area\n",
    "held_pod['label'] = 'held_POD'\n",
    "\n",
    "\n",
    "# Find the difference: the areas in buffered_gdf not covered by held_pod\n",
    "#breached_pod = test_pod.geometry.difference(held_pod.unary_union)\n",
    "#breached_pod_gdf = gpd.GeoDataFrame(geometry=breached_pod, crs=buffered_gdf.crs)\n",
    "#breached_pod_gdf['label'] = 'breached_POD'\n",
    "\n",
    "#breached_pod = gpd.clip(inward_buffer_BREACH, test_pod)\n",
    "# Convert inward_buffer_BREACH to a GeoDataFrame if it's not already\n",
    "if isinstance(inward_buffer_BREACH, gpd.GeoSeries):\n",
    "    inward_buffer_BREACH_gdf = gpd.GeoDataFrame(geometry=inward_buffer_BREACH)\n",
    "else:\n",
    "    inward_buffer_BREACH_gdf = inward_buffer_BREACH\n",
    "\n",
    "# Now use gpd.overlay with GeoDataFrames\n",
    "breached_pod = gpd.overlay(inward_buffer_BREACH_gdf, test_pod, how='intersection')\n",
    "\n",
    "#breached_pod = gpd.overlay(inward_buffer_BREACH, test_pod, how='intersection')\n",
    "\n",
    "\n",
    "breached_pod_gdf = gpd.GeoDataFrame(geometry=breached_pod, crs=buffered_gdf.crs)\n",
    "breached_pod_gdf['label'] = 'breached_POD'\n",
    "\n",
    "# Generate points along held_pod geometry\n",
    "held_pod_points = generate_points_along_line(held_pod.geometry.iloc[0], interval_distance)\n",
    "\n",
    "# Generate points along breached_pod_gdf geometry\n",
    "breached_pod_points = generate_points_along_line(breached_pod_gdf.geometry.iloc[0], interval_distance)\n",
    "\n",
    "# Extract the boundaries of MultiPolygons in fire_perimeters\n",
    "fire_perimeter_boundaries = fire_perimeters.boundary\n",
    "\n",
    "# Generate points along the fire perimeter boundaries\n",
    "fire_perimeter_points = []\n",
    "for boundary in fire_perimeter_boundaries:\n",
    "    points = generate_points_along_line(boundary, interval_distance)\n",
    "    fire_perimeter_points.extend(points)\n",
    "\n",
    "# Assuming you have 'held_pod_points', 'breached_pod_points', and 'fire_perimeter_points' GeoSeries objects\n",
    "held_pod_df = gpd.GeoDataFrame(geometry=held_pod_points)\n",
    "breached_pod_df = gpd.GeoDataFrame(geometry=breached_pod_points)\n",
    "fire_perimeter_df = gpd.GeoDataFrame(geometry=fire_perimeter_points)\n",
    "\n",
    "# Concatenate the three DataFrames\n",
    "merged_df = pd.concat([held_pod_df, breached_pod_df, fire_perimeter_df])\n",
    "\n",
    "# Create a new GeoSeries from the concatenated DataFrame\n",
    "merged_geo_series = gpd.GeoSeries(merged_df['geometry'])\n",
    "print(f\"number of held, breached, and fire perimeter points: {len(merged_geo_series)}\")\n",
    "\n",
    "# Create a list of labels for 'held_POD', 'breached_POD', and 'fire_perimeter' GeoDataFrames\n",
    "held_labels = [1] * len(held_pod_points)\n",
    "breached_labels = [0] * len(breached_pod_points)\n",
    "fire_labels = [2] * len(fire_perimeter_points)\n",
    "labels = held_labels + breached_labels + fire_labels\n",
    "\n",
    "# Data for the new label\n",
    "data = {\n",
    "    'labels': labels,\n",
    "    'merged_geo_series_x': merged_geo_series.x,\n",
    "    'merged_geo_series_y': merged_geo_series.y\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['labels'] = df['labels'].astype(np.int16)\n",
    "df['merged_geo_series_x'] = df['merged_geo_series_x'].astype(np.float32)\n",
    "df['merged_geo_series_y'] = df['merged_geo_series_y'].astype(np.float32)\n",
    "\n",
    "minx, miny, maxx, maxy = test_pod.total_bounds\n",
    "gdf_extent = [minx, maxx, miny, maxy]\n",
    "print(gdf_extent)\n",
    "\n",
    "# Plot the points and color them based on labels\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot the fire perimeter polyline with a dashed line\n",
    "fire_perimeters.plot(ax=plt.gca(), color='lightgray', linewidth=2, linestyle='--', label='Fire Perimeter', alpha=0.5)\n",
    "\n",
    "# Plot the test_pod polyline\n",
    "test_pod.plot(ax=plt.gca(), color='black', linewidth=2, label='Pod Boundary')\n",
    "\n",
    "# Separate the points based on labels\n",
    "held_points = df[df['labels'] == 1]\n",
    "breached_points = df[df['labels'] == 0]\n",
    "fire_points = df[df['labels'] == 2]\n",
    "\n",
    "#########################################################\n",
    "#########################################################\n",
    "#########################################################\n",
    "# Create a function to calculate the distance between two points\n",
    "def calculate_distance(point1, point2):\n",
    "    return distance.euclidean(point1, point2)\n",
    "\n",
    "# Create NumPy arrays to store coordinates and labels\n",
    "coordinates = df[['merged_geo_series_x', 'merged_geo_series_y']].values\n",
    "labels = df['labels'].values\n",
    "\n",
    "# Create an array to track labels to be removed\n",
    "to_remove = np.zeros(len(coordinates), dtype=bool)\n",
    "\n",
    "# Iterate through the DataFrame to find label 2 to be removed\n",
    "for i in range(len(coordinates)):\n",
    "    if labels[i] == 2:\n",
    "        point1 = coordinates[i]\n",
    "        close_to_label_0_1 = np.any(np.logical_and(labels != 2, np.linalg.norm(coordinates - point1, axis=1) <= threshold_distance))\n",
    "        if close_to_label_0_1:\n",
    "            to_remove[i] = True\n",
    "\n",
    "# Remove the rows with labels 2 that are within 300 meters of a 0 or 1\n",
    "filtered_coordinates = coordinates[~to_remove]\n",
    "filtered_labels = labels[~to_remove]\n",
    "\n",
    "# Create a new DataFrame\n",
    "filtered_df = pd.DataFrame({\n",
    "    'labels': filtered_labels,\n",
    "    'merged_geo_series_x': filtered_coordinates[:, 0],\n",
    "    'merged_geo_series_y': filtered_coordinates[:, 1]\n",
    "})\n",
    "\n",
    "# Convert the DataFrame 'df' to a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(filtered_df, geometry=gpd.points_from_xy(filtered_df['merged_geo_series_x'], filtered_df['merged_geo_series_y']), crs=utm_crs)\n",
    "\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "gdf.to_file(output_shapefile_path_PTS)\n",
    "\n",
    "#########################################################\n",
    "#########################################################\n",
    "#########################################################\n",
    "\n",
    "plt.scatter(held_points['merged_geo_series_x'], held_points['merged_geo_series_y'], c='green', label='Held', marker='o')\n",
    "plt.scatter(breached_points['merged_geo_series_x'], breached_points['merged_geo_series_y'], c='red', label='Breach', marker='x')\n",
    "plt.scatter(filtered_df['merged_geo_series_x'][filtered_df['labels'] == 2], filtered_df['merged_geo_series_y'][filtered_df['labels'] == 2], c='blue', label='Fire Perimeter')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Easting')\n",
    "plt.ylabel('Northing')\n",
    "plt.xlim(minx - 500, maxx + 500)\n",
    "plt.ylim(miny - 500, maxy + 500)\n",
    "plt.legend(loc='best')\n",
    "\n",
    "#plt.savefig(r'C:\\Users\\magst\\Desktop\\LIDAR\\FIGURES\\overlayed.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "#\n",
    "##\n",
    "###\n",
    "####\n",
    "#####\n",
    "######\n",
    "#######\n",
    "\n",
    "#converted_held_pod_points = np.array([(point.x, point.y) for point in held_pod_points])\n",
    "#converted_breached_pod_points = np.array([(point.x, point.y) for point in breached_pod_points])\n",
    "fireline_point = filtered_df[filtered_df['labels'] == 2]\n",
    "converted_fireline_points = fireline_point[['merged_geo_series_x', 'merged_geo_series_y']].values\n",
    "\n",
    "breach_point = filtered_df[filtered_df['labels'] == 0]\n",
    "converted_breach_points = breach_point[['merged_geo_series_x', 'merged_geo_series_y']].values\n",
    "\n",
    "held_point = filtered_df[filtered_df['labels'] == 1]\n",
    "converted_held_points = held_point[['merged_geo_series_x', 'merged_geo_series_y']].values\n",
    "\n",
    "# # Create an empty list to hold the LineString objects\n",
    "# line_strings = []\n",
    "\n",
    "test_pod_points = filtered_df[['merged_geo_series_x', 'merged_geo_series_y']].to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# for point in np.vstack((converted_fireline_points, converted_breach_points, converted_held_points)):\n",
    "#     start, end = find_perpendicular_points(point, test_pod_points, perp_length)\n",
    "    \n",
    "#     # Check if start and end points have valid coordinates (not NaN or infinite)\n",
    "#     if np.all(np.isfinite(start)) and np.all(np.isfinite(end)):\n",
    "#         line = LineString([start, end])\n",
    "#         line_strings.append(line)\n",
    "\n",
    "# # Create a GeoDataFrame with the line segments\n",
    "# gdf = gpd.GeoDataFrame(geometry=line_strings)\n",
    "\n",
    "# # Set a coordinate reference system (CRS) for the GeoDataFrame\n",
    "# gdf.crs = utm_crs\n",
    "\n",
    "# #If df['labels'] is the same length as gdf and corresponds to each line\n",
    "# #Reset index to ensure proper alignment when adding labels\n",
    "# filtered_df.reset_index(drop=True, inplace=True)\n",
    "# gdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# #Add labels to your GeoDataFrame\n",
    "# gdf['label'] = filtered_df['labels']\n",
    "\n",
    "\n",
    "# gdf.to_file(output_shp_path_PERPLINE)\n",
    "# print(\"Shapefile with labels saved.\")\n",
    "\n",
    "\n",
    "# Create an empty list to hold the LineString objects for fireline\n",
    "fireline_line_strings = []\n",
    "\n",
    "for point in converted_fireline_points:\n",
    "    start, end = find_perpendicular_points(point, test_pod_points, perp_length)\n",
    "    \n",
    "    # Check if start and end points have valid coordinates (not NaN or infinite)\n",
    "    if np.all(np.isfinite(start)) and np.all(np.isfinite(end)):\n",
    "        line = LineString([start, end])\n",
    "        fireline_line_strings.append(line)\n",
    "\n",
    "# Create a GeoDataFrame for fireline\n",
    "fireline_gdf = gpd.GeoDataFrame(geometry=fireline_line_strings)\n",
    "fireline_gdf.crs = utm_crs\n",
    "fireline_gdf['label'] = 2  # Assign label 2 for fireline\n",
    "\n",
    "# Create an empty list to hold the LineString objects for breach\n",
    "breach_line_strings = []\n",
    "\n",
    "for point in converted_breach_points:\n",
    "    start, end = find_perpendicular_points(point, test_pod_points, perp_length)\n",
    "    \n",
    "    # Check if start and end points have valid coordinates (not NaN or infinite)\n",
    "    if np.all(np.isfinite(start)) and np.all(np.isfinite(end)):\n",
    "        line = LineString([start, end])\n",
    "        breach_line_strings.append(line)\n",
    "\n",
    "# Create a GeoDataFrame for breach\n",
    "breach_gdf = gpd.GeoDataFrame(geometry=breach_line_strings)\n",
    "breach_gdf.crs = utm_crs\n",
    "breach_gdf['label'] = 0  # Assign label 0 for breach\n",
    "\n",
    "# Create an empty list to hold the LineString objects for held\n",
    "held_line_strings = []\n",
    "\n",
    "for point in converted_held_points:\n",
    "    start, end = find_perpendicular_points(point, test_pod_points, perp_length)\n",
    "    \n",
    "    # Check if start and end points have valid coordinates (not NaN or infinite)\n",
    "    if np.all(np.isfinite(start)) and np.all(np.isfinite(end)):\n",
    "        line = LineString([start, end])\n",
    "        held_line_strings.append(line)\n",
    "\n",
    "# Create a GeoDataFrame for held\n",
    "held_gdf = gpd.GeoDataFrame(geometry=held_line_strings)\n",
    "held_gdf.crs = utm_crs\n",
    "held_gdf['label'] = 1  # Assign label 1 for held\n",
    "\n",
    "# Concatenate the GeoDataFrames for fireline, breach, and held\n",
    "gdf = pd.concat([fireline_gdf, breach_gdf, held_gdf], ignore_index=True)\n",
    "\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "gdf.to_file(output_shp_path_PERPLINE)\n",
    "print(\"Shapefile with labels saved.\")\n",
    "\n",
    "\n",
    "#######\n",
    "######\n",
    "#####\n",
    "####\n",
    "###\n",
    "##\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b08f9a-9f88-46e2-8745-90ef2d3fb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pygeos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc452b0c-affc-48ee-890e-61a702273904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fa7bfb-cd50-4cd3-97b4-1e704589589a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd4335-cf7e-41f8-aafa-fed828439ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8b271-b063-4cb2-a6dd-298c483dbf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f60e9-b046-48d5-bf1d-6c4969986069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
